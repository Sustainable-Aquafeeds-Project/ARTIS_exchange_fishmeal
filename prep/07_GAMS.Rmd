---
title: "Model and predict trimmings proportions"
output: html_document
date: "2024-08-22"
editor_options: 
  chunk_output_type: inline
---

## Summary

Use GAMs to predict trimmings proportions

## Setup

```{r setup}

library(here)
library(tidyverse)
library(glue)
library(sf)
library(devtools)
library(janitor)
library(countrycode)
library(qs)
library(mgcv)
library(scales)
library(tictoc)
library(parallel)
library(performance)
library(gratia)


source(here("R/directories.R"))


artis_taxa <- read.csv(file.path(artis_dir, "artis_full_data/data/attribute tables/sciname.csv")) ## read in attribute table with common names

countries <- read.csv(here("data/countries.csv")) ## artis countries with info

artis_trimmings <- qs::qread(here("int/artis_trimmings_fillet_prices_consumption.qs")) %>%
  mutate(filleted = ifelse(filleted == "yes", 1, 0)) %>%
  left_join(artis_taxa)

```


Model Fitting GAMs with beta distribution


```{r}
artis_trimmings_beta <- artis_trimmings %>% 
  mutate(trim_prop_beta = case_when(
    trim_prop_gf == 0 ~ trim_prop_gf + 0.000000001,
        trim_prop_gf == 1 ~ trim_prop_gf - 0.000000001, # regular beta regression can't take 0 or 1
    TRUE ~ trim_prop_gf
  )) %>%
    mutate(
      # Convert only necessary columns to factors
      filleted = as.factor(filleted),
      source_country_iso3c = as.factor(source_country_iso3c),
      family = as.factor(family),
      year = as.numeric(as.character(year))  # Keep year numeric for smoother
    ) %>%
    # Remove any unnecessary columns
    distinct(trim_prop_beta, price_gf, filleted, 
           source_country_iso3c, family, year) %>%
    # Remove NA values upfront
    na.omit()

# Function to create model formula
create_formula <- function(predictors) {
  # Always include s(price_gf) if price_gf is in predictors
  terms <- character()
  
  if("price_gf" %in% predictors) {
    terms <- c(terms, "s(price_gf)")
    predictors <- setdiff(predictors, "price_gf")
  }
  
  # Add remaining predictors as linear terms
  if(length(predictors) > 0) {
    terms <- c(terms, predictors)
  }
  
  # Combine terms with +
  rhs <- paste(terms, collapse = " + ")
  
  # Create and return the full formula
  as.formula(paste("trim_prop_beta ~", rhs))
}

# Set up control parameters for parallel processing
ctrl <- list(nthreads = 6) # use 6 cores, because 8 fails sometimes. 6 seems to be the sweet spot for me. 

# Define all possible predictor variables (excluding the response variable)
predictors <- c("price_gf", "filleted", "source_country_iso3c", "family", "year")

all_combinations <- list()
for(i in 1:length(predictors)) {
  all_combinations <- c(all_combinations, 
                       combn(predictors, i, simplify = FALSE))
}

# Function to run and save a single model
run_and_save_model <- function(predictor_set, data) {
  
  # predictor_set = all_combinations[[2]]
  # data = artis_trimmings_beta_2
  
    # Create descriptive filename
  filename <- paste0("int/models/gam_model_", 
                    paste(predictor_set, collapse = "_"),
                    ".qs")
  
    if(file.exists(here(filename))) {
    cat("\nSkipping model with predictors:", 
        paste(predictor_set, collapse = ", "), 
        "- already exists\n")
        return(NULL)  # Exit the function
  }
  
  formula <- create_formula(predictor_set)
  
  # Print progress
  cat("\nFitting model", "with predictors:", 
      paste(predictor_set, collapse = ", "), "\n")
  
  # Time the model fitting
  tic()
  
  model <- try({
    gam(formula,
        data = data,
        family = betar(),
        na.action = na.exclude,
        control = ctrl)
  })
  
  toc()
  
  if(!inherits(model, "try-error")) {

    # Save the model
    qs::qsave(model, here(filename))
    
    cat("Model saved as:", filename, "\n")
  } else {
    cat("Error fitting model with predictors:", 
        paste(predictor_set, collapse = ", "), "\n")
  }
  
  return(model)
}


# Main execution
run_all_models <- function(data) {
  
  # Run models for all combinations
  models <- list()
  for(i in seq_along(all_combinations)) {
    # i = 1
    models[[i]] <- run_and_save_model(all_combinations[[i]], 
                                     data)
  }
  
  return(models)
}

# Example usage:
if(TRUE) {  # Set to TRUE to run
  # Assuming your data is in artis_trimmings_beta_2
  models <- run_all_models(artis_trimmings_beta)
}

test2 <- qs::qread(here("int/models/gam_model_price_gf_filleted_source_country_iso3c_year.qs"))
AIC(test2)
```


Validation and diagnostics 


Results: 
 - I'm seeing that the best models according to AIC and BIC have lower deviance explained, while the worst models for AIC and BIC have high deviance explained.
 
Predictive Modeling: If prediction is the goal, prioritize models with better AIC, BIC, or GCV scores, even if deviance explained is low.
Explanatory Modeling: If understanding the relationships between predictors and the response is key, higher deviance explained might be more important, but ensure the model is interpretable and not overfitting.

I need to do cross validation. 

```{r}
file_paths <- list.files(here("int/models/"), full.names = TRUE)
file_paths <- file_paths[!grepl("diagnostics", file_paths)]

# Read in each model and store in a list
models <- lapply(file_paths, qs::qread)

# Combine all models by binding their rows
# Ensure the models have consistent structure
combined_models <- lapply(models, function(mod) {
  
 # mod = models[[1]]
  # Extracting relevant data from each model into a consistent structure
  tibble::tibble(
    aic = AIC(mod),
    bic = BIC(mod),
    dev_explained = summary(mod)$dev.expl,
    gcv = mod$gcv.ubre,
    edf = sum(mod$edf),
    k_index = k.check(mod)[[3]],
    formula = paste(deparse(formula(mod)), collapse = " ") # Collapse formula into a single string
  )
}) %>% bind_rows(.id = "model")

write.csv(combined_models, here("int/models/diagnostics/all_model_diagnostics.csv"), row.names = FALSE)




plot_residual_diagnostics <- function(mod) {
  # Get the model formula for the title
  title <- paste(deparse(formula(mod)), collapse = " ")
  
  # Sanitize the title
  sanitized_title <- gsub("\\s+", "_", title)  # Replace spaces with underscores
  sanitized_title <- gsub("[^[:alnum:]_]", "_", sanitized_title)  # Replace non-alphanumeric characters with underscores
  sanitized_title <- gsub("_+", "_", sanitized_title)  # Replace multiple underscores with one
  
  # Create the PDF file for diagnostics
  pdf(here::here(glue::glue("int/models/diagnostics/diagnostics_{sanitized_title}.pdf")))
  
  # Set up the layout and adjust margins for the title
  par(mfrow = c(2, 2))  # Increase the top margin even more (10)
  
  # Add the filename as a header on the first page using grid
  grid::grid.text(title, x = 0.5, y = 0.97, gp = grid::gpar(fontsize = 11))
  
  # Basic GAM checks
  mgcv::gam.check(mod)

  # Check if the model has smooth terms
  if (length(mod$smooth) > 0) {
    # Plot smooth terms and residuals if they exist
    plot(mod, pages = 1, residuals = TRUE)
    # Partial effects (only available for models with smooth terms)
    gratia::draw(mod)
    title(paste("Partial Effects:"))  # Add title to this plot
  } else {
    message("No smooth terms in the model. Skipping smooth term and partial effects plots.")
  }
  
  # Close the PDF device
  dev.off()
}


lapply(models, plot_residual_diagnostics)

library(pdftools)

## lets compile into a master pdf
# List of PDFs
pdf_list <- list.files(here("int/models/diagnostics/"), pattern = ".pdf", full.names = TRUE)


pdf_combine(pdf_list, output = here("int/models/diagnostics/combined.pdf"))


```

cross validation 
 - Choose best models? I want to cut this down as much as possible, because some of these models take really long to run (~7-8 hours), and running them 5 times might take quite a long time. 

```{r}
ctrl <- list(nthreads=6) # try with 8 cores?

file_paths <- list.files(here("int/models/"), full.names = TRUE)
file_paths <- file_paths[!grepl("diagnostics", file_paths)]
models_run <- lapply(file_paths, qs::qread)
formulas <- lapply(models_run, formula)

all_diagnostics <- read.csv(here("int/models/diagnostics/all_model_diagnostics.csv"))
   
choose_models <- all_diagnostics %>%
  arrange(aic) %>% # ok looks like the best models (according to AIC and BIC) are the first 9. Let's do cv on these
  slice(1:9) %>% 
  pull(formula) 


perform_cv <- function(data, k = 5) {
  
  # data = artis_trimmings_beta
  # k=5
  set.seed(123)
  folds <- sample(1:k, nrow(data), replace = TRUE)
  cv_results <- list()
  
  for(i in 1:k) {
    # Split data
    
    # i=1
    train <- data[folds != i, ]
    test <- data[folds == i, ]
    
  cv_models <- lapply(choose_models, function(f) {
      tryCatch(
        
        gam(as.formula(f), data = train, family = betar(), control = ctrl),
        error = function(e) e # Return error object if fitting fails
      )
    })
    
    # Calculate errors
    cv_results[[i]] <- lapply(cv_models, function(m) {
      if(!inherits(m, "try-error")) {
        # m = models[[1]]
        pred <- predict(m, newdata = test, type = "response")
        mse <- mean((test$trim_prop_beta - pred)^2, na.rm = TRUE)
        mae <- mean(abs(test$trim_prop_beta - pred), na.rm = TRUE)
        return(c(mse = mse, mae = mae))
      } else {
        return(c(mse = NA, mae = NA))
      }
    })
  }
  
  # Summarize results
  # Summarize results
  cv_summary <- do.call(rbind, lapply(cv_results, function(x) {
    do.call(rbind, x)
    
  }))
  
  colMeans(cv_summary, na.rm = TRUE)
}



perform_cv(artis_trimmings_beta_2)

```

```{r}
save_analysis <- function(data) {

  # Save model comparison
  write.csv(model_comparison, 
            here("int/models/model_comparison.csv"),
            row.names = FALSE)
  
  # Save cross-validation results
  write.csv(cv_results,
            here("int/models/cross_validation.csv"),
            row.names = FALSE)

  
  # Generate summary report
  sink(here("int/models/analysis_summary.txt"))
  
  cat("Fishmeal Trimmings GAM Analysis Summary\n")
  cat("=====================================\n\n")
  
  cat("1. Model Comparison\n")
  cat("-----------------\n")
  print(model_comparison)
  cat("\n\n")
  
  cat("2. Cross-Validation Results\n")
  cat("------------------------\n")
  print(cv_results)
  cat("\n\n")
  
  
  cat("3. Model Selection Recommendations\n")
  cat("------------------------------\n")
  
  # Add model selection recommendations based on results
  best_aic <- model_comparison$model[which.min(model_comparison$aic)]
  best_cv <- names(which.min(colMeans(cv_results)))
  
  cat(sprintf("Best model by AIC: %s\n", best_aic))
  cat(sprintf("Best model by cross-validation: %s\n", best_cv))
  
  sink()
}

save_analysis()

```






3. Gap Filling

Fill using a hierarchical model approach based on AIC: 
 - gam with price, filleted, year, and source country has the lowest AIC, best log likelihood, and lowest MSE and MAE from cross validation 
 

```{r}
gam_model2 <- qread(here("int/gam_model2_beta.qs"))

predict_data_2 <- artis_trimmings %>% 
  mutate(gam_preds_2 = predict(gam_model2, newdata = ., type = "response")) 


fin_data <- predict_data_2 %>%
  mutate(trim_prop_gf = ifelse(is.na(trim_prop_gf), gam_preds_2, trim_prop_gf),
         trim_prop_gf_flag = ifelse(is.na(trim_prop_gf), "GAM model", trim_prop_gf_flag))

 qsave(fin_data, here("int/predicted_trimmings_values_beta.qs"))

```


Allocation to product weight 

```{r}

predict_data_all_gf_fin <- qread(here("int/predicted_trimmings_values_beta.qs"))


all_data_gf <- predict_data_all_gf_fin %>%
  mutate(trim_liveweight = trim_prop_gf*live_weight_t,
    trim_product = trim_prop_gf*product_weight_t, 
    wholefish_liveweight = (1-trim_prop_gf)*live_weight_t,
    wholefish_product = (1-trim_prop_gf)*product_weight_t) %>%
  left_join(artis_taxa) %>%
    dplyr::select(year, source_country_iso3c, exporter_iso3c, consumer_iso3c, dom_source, sciname, common_name, habitat, method, trim_prop_gf, trim_liveweight, trim_product, wholefish_liveweight, wholefish_product, phylum, method_trim_gf = trim_prop_gf_flag) %>%
  pivot_longer(., cols = c(trim_product, wholefish_product), names_to = "fishmeal_type", values_to = "product_weight_t") %>%
  mutate(live_weight_t = product_weight_t*2.975207,
         fishmeal_type = ifelse(fishmeal_type == "trim_product", "trimmings", "whole fish")) 

for(year_loop in 1996:2020){

#  year_loop = 2020
artis_all_2020 <- all_data_gf %>%
  filter(year == year_loop,
         phylum == "chordata") %>%
  left_join(countries, by = c("source_country_iso3c" = "iso3c")) %>%
  mutate(owid_region = ifelse(is.na(owid_region), "unknown", owid_region)) %>%
    mutate(owid_region = ifelse(owid_region == "Other nei", "unknown", owid_region))


total_product_weight <- sum(artis_all_2020$product_weight_t, na.rm = TRUE) # 6187648


## Let's make a bar plot and have x axis be the type of fish meal, y axis the proportion it represents, and fill by continent


bar_plot_df <- artis_all_2020 %>% 
  filter(!is.na(trim_prop_gf)) %>% # shouldn't be any
  group_by(fishmeal_type, owid_region) %>%
  summarise(total = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(total_product_t = total_product_weight) %>%
  mutate(prop = total/total_product_t) %>%
  mutate(perc = prop * 100) %>% # Convert to percentage
  mutate(label = paste0(round(perc, 1), "%")) %>%
  arrange(desc(fishmeal_type))  %>%
  filter(prop > 0) %>%
  arrange(-prop) 

## oceania: #9F6144
## Africa: #A660A1
## Asia: #3F8D87
## South America: #8F464E
## North America: #E47669
## Europe: #5E74A1
## unknown: #808080
## Other_nei: #808080
  
wholefish_prop <- bar_plot_df %>% filter(fishmeal_type == "whole fish") %>% pull(prop) %>% sum()

ggplot(bar_plot_df, aes(x = reorder(fishmeal_type, -prop), y = prop, fill = owid_region)) +
  geom_bar(stat = "identity", color = "white") + 
 scale_fill_manual(values = c("#A660A1", "#3F8D87", "#5E74A1", "#E47669", "#9F6144", "#8F464E", "#808080")) +
  theme_classic() +
  labs(fill = "Region", y = "Proportion of global trade", x = "Fishmeal type") + 
    scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0))

ggsave(glue(here("outputs/figs/finfish/props_{wholefish_prop}_{year_loop}.png")))

}


library(scales)
yearly_table <- all_data_gf %>%
  group_by(year, fishmeal_type) %>%
  summarise(total = sum(product_weight_t)) %>%
  ungroup() %>%
  pivot_wider(names_from = fishmeal_type, values_from = total) %>% 
  mutate(total = `whole fish`+trimmings) %>%
  mutate(prop_whole = `whole fish`/total,
         prop_trim = trimmings/total) %>%
    mutate(perc_whole = percent(`whole fish` / total, accuracy = 0.1),
         perc_trim = percent(trimmings / total, accuracy = 0.1)) %>%
  dplyr::select(year, perc_whole, perc_trim)

print(yearly_table)


yearly_table <- all_data_gf %>%
  filter(phylum == "chordata") %>%
   group_by(year, fishmeal_type) %>%
  summarise(total = sum(product_weight_t)) %>%
  ungroup() %>%
  pivot_wider(names_from = fishmeal_type, values_from = total) %>% 
  mutate(total = `whole fish`+trimmings) %>%
  mutate(prop_whole = `whole fish`/total,
         prop_trim = trimmings/total) %>%
    mutate(perc_whole = percent(`whole fish` / total, accuracy = 0.1),
         perc_trim = percent(trimmings / total, accuracy = 0.1)) %>%
  dplyr::select(year, perc_whole, perc_trim)

print(yearly_table)

```

Plots

```{r}
## look at proportions over time 

over_time <- all_data_gf %>%
  group_by(year, fishmeal_type) %>%
  summarise(product_t = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(total_t = sum(product_t)) %>%
  ungroup() %>%
  mutate(prop = product_t/total_t)

ggplot(over_time, aes(x = year, y = prop, color = fishmeal_type)) +
  # geom_point() +
  geom_line() +
    geom_text(data = over_time, aes(label = round(prop,2)), 
            # hjust = -0.2, 
            vjust = -0.5,
            size = 3) + 
  theme_bw() +
  labs(title = "Global fishmeal production over time (1996-2020)", x = "Year", y = "Proportion of fishmeal", caption = "All species")


over_time <- all_data_gf %>%
  filter(phylum %in% c("chordata", NA)) %>% # ok only finfish (or NA)
  filter(!(common_name %in% c("sea urchins", "saltwater mussels", "sea lamprey", "lampreys nei"))) %>%
  group_by(year, fishmeal_type) %>%
  summarise(product_t = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(total_t = sum(product_t)) %>%
  ungroup() %>%
  mutate(prop = product_t/total_t)

ggplot(over_time, aes(x = year, y = prop, color = fishmeal_type)) +
 # geom_point() +
  geom_line() +
  geom_text(data = over_time, aes(label = round(prop,2)), 
            # hjust = -0.2, 
            vjust = -0.5,
            size = 3) + 
  theme_bw() +
  labs(title = "Global fishmeal production over time (1996-2020)", x = "Year", y = "Proportion of fishmeal", caption = "Finfish only")


over_time <- all_data_gf %>%
  group_by(year, fishmeal_type, phylum) %>%
  summarise(product_t = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(total_t = sum(product_t)) %>%
  ungroup() %>%
  mutate(prop = product_t/total_t)

ggplot(over_time, aes(x = year, y = product_t, color = fishmeal_type)) +
 #geom_point() +
  geom_line() +
  facet_wrap(~phylum) + 
  theme_bw() +
  labs(title = "Global fishmeal production over time (1996-2020)", x = "Year", y = "Product weight (tonnes)")


over_time <- all_data_gf %>%
  filter(phylum %in% c("chordata", NA)) %>% # ok only finfish (or NA)
  filter(!(common_name %in% c("sea urchins", "saltwater mussels", "sea lamprey", "lampreys nei"))) %>%
  filter(source_country_iso3c == "CHN") %>%
  group_by(year, fishmeal_type) %>%
  summarise(product_t = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(total_t = sum(product_t)) %>%
  ungroup() %>%
  mutate(prop = product_t/total_t)

ggplot(over_time, aes(x = year, y = prop, color = fishmeal_type)) +
  geom_line() +
  geom_text(data = over_time, aes(label = round(prop,2)), 
            # hjust = -0.2, 
            vjust = -0.5,
            size = 3) + 
  theme_bw() +
  labs(title = "Finfish fishmeal production over time (1996-2020) in China", x = "Year", y = "Proportion of fishmeal", caption = "Finfish only")


over_time <- all_data_gf %>%
  #filter(phylum %in% c("chordata", NA)) %>% # ok only finfish (or NA)
  #filter(!(common_name %in% c("sea urchins", "saltwater mussels", "sea lamprey", "lampreys nei"))) %>%
  filter(source_country_iso3c == "CHN") %>%
  group_by(year, fishmeal_type, phylum) %>%
  summarise(product_t = sum(product_weight_t, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(total_t = sum(product_t)) %>%
  ungroup() %>%
  mutate(prop = product_t/total_t)

ggplot(over_time, aes(x = year, y = product_t, color = fishmeal_type)) +
  geom_line() +
  facet_wrap(~phylum) + 
  theme_bw() +
  labs(title = "Fishmeal production over time (1996-2020) in China", x = "Year", y = "Product weight (tonnes)")

```

archive: 

```{r}
gam_model <- qread(here("int/gam_model1_beta.qs"))

## first we need to exclude any observations that don't have levels in the data for source_country_iso3c AND for family, since we can't predict for missing factor levels

# Assuming your model is stored in the variable `gam_model`
coefficients <- coef(gam_model)

# Extract the names of the coefficients
coef_names <- names(coefficients)  

# Filter for source_country_iso3c coefficients
source_country_coefs <- grep("^source_country_iso3c", coef_names, value = TRUE)

# Extract the country codes
source_country_iso3c_codes <- gsub("source_country_iso3c", "", source_country_coefs)

# Filter for source_country_iso3c coefficients
family_coefs <- grep("^family", coef_names, value = TRUE)

# Extract the country codes
family_codes <- gsub("family", "", family_coefs)
  
predict_data_1 <- artis_trimmings %>% 
  filter(source_country_iso3c %in% c(source_country_iso3c_codes)) %>%
  filter(family %in% c(family_codes)) %>% # ok so we're mostly missing family names
  mutate(gam_preds_1 = predict(gam_model, newdata = ., type = "response"))

## next exclude any observations that don't have levels in the data for iso3c

gam_model2 <- qread(here("int/gam_model2_beta.qs"))

predict_data_2 <- artis_trimmings %>% 
  filter(source_country_iso3c %in% c(source_country_iso3c_codes)) %>%
  mutate(gam_preds_2 = predict(gam_model2, newdata = ., type = "response"))

## next exclude any observations that don't have levels in the data for family

gam_model3 <- qread(here("int/gam_model3_beta.qs"))

predict_data_3 <- artis_trimmings %>% 
  filter(family %in% c(family_codes)) %>% # ok so we're mostly missing family names
  mutate(gam_preds_3 = predict(gam_model3, newdata = ., type = "response"))


## Now make predictions for all data

gam_model4 <- qread(here("int/gam_model4_beta.qs"))

predict_data_4 <- artis_trimmings %>% 
  mutate(gam_preds_4 = predict(gam_model4, newdata = ., type = "response"))

## now join all of these predictions to the full dataset

predict_data_all <- predict_data_4 %>%
  left_join(predict_data_1) %>%
  left_join(predict_data_2) %>%
  left_join(predict_data_3) %>%
 mutate(
    # Start by assuming that trim_prop_gf_fin is the same as trim_prop_gf
    trim_prop_gf_fin = ifelse(!is.na(trim_prop_gf), trim_prop_gf, NA),
    
    # Add the initial gapfill flag
    trim_prop_gf_flag = ifelse(!is.na(trim_prop_gf), trim_prop_gf_flag, NA),
    
    # Fill missing values with gams_preds_1
    trim_prop_gf_fin = ifelse(is.na(trim_prop_gf_fin), gam_preds_1, trim_prop_gf_fin),
    trim_prop_gf_flag = ifelse(is.na(trim_prop_gf_fin) & is.na(trim_prop_gf_flag), "GAM1_all", trim_prop_gf_flag),
    
    # Fill missing values with gams_preds_3
    trim_prop_gf_fin = ifelse(is.na(trim_prop_gf_fin), gam_preds_2, trim_prop_gf_fin),
    trim_prop_gf_flag = ifelse(is.na(trim_prop_gf_fin) & is.na(trim_prop_gf_flag), "GAM2_iso3c", trim_prop_gf_flag),
    
    # Fill missing values with gams_preds_2
    trim_prop_gf_fin = ifelse(is.na(trim_prop_gf_fin), gam_preds_3, trim_prop_gf_fin),
    trim_prop_gf_flag = ifelse(is.na(trim_prop_gf_fin) & is.na(trim_prop_gf_flag), "GAM3_family", trim_prop_gf_flag),
    
    # Fill missing values with gams_preds_4
    trim_prop_gf_fin = ifelse(is.na(trim_prop_gf_fin), gam_preds_4, trim_prop_gf_fin),
    trim_prop_gf_flag = ifelse(is.na(trim_prop_gf_fin) & is.na(trim_prop_gf_flag), "GAM4", trim_prop_gf_flag)
  ) %>% 
  dplyr::select(-isscaap, -kingdom, -phylum, -superclass, -class, -order, -subfamily, -genus)


predict_data_all_gf_fin <- predict_data_all %>% 
  dplyr::select(-gam_preds_1, -gam_preds_2, -gam_preds_3, -gam_preds_4, -trim_prop_gf) %>% 
  distinct()
qsave(predict_data_all_gf_fin, here("int/predicted_trimmings_values_beta.qs"))

```