---
title: "Pull ARTIS data"
output: html_document
date: "2024-06-12"
---

## Summary

Pulling and saving full ARTIS database provided on KNB: 
 - https://knb.ecoinformatics.org/view/doi:10.5063/F1CZ35N7 

We will use the example script that Jessica has provided to pull trade information for fish meal and fish fillets 
 - https://github.com/Seafood-Globalization-Lab/exploreARTIS/blob/main/scripts/filter_bulk_artis.R

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(glue)
library(sf)
library(devtools)
library(janitor)
library(qs)

rdsi_dir <- file.path("/mnt/rdsi/raw_data")

artis_dir <- file.path(rdsi_dir, "ARTIS")

codes <- read.csv(file.path(artis_dir, "artis_full_data/data/attribute tables/products.csv"))

```

First, we save ARTIS data from KNB

```{r}
# Example script for loading and saving full ARTIS data from KNB

fillet_codes <- codes %>% 
  filter(presentation == "fillet") %>%
      mutate(hs6 = as.character(hs6)) %>%
    mutate(hs6 = case_when(
      str_length(hs6) == 5 ~ paste("0", hs6, sep = ""),
      TRUE ~ hs6
    )) %>%
  distinct(hs6, description)

write.csv(fillet_codes, here("outputs/SI_table_fillets.csv"), row.names = FALSE)

fillet_codes <- codes %>% 
  filter(presentation == "fillet") %>%
      mutate(hs6 = as.character(hs6)) %>%
    mutate(hs6 = case_when(
      str_length(hs6) == 5 ~ paste("0", hs6, sep = ""),
      TRUE ~ hs6
    )) %>%
  pull(hs6) %>%
  unique()


# Set data directory where artis data is loaded
datadir <- file.path(artis_dir, "artis_full_data/data/trade") 
  
intdir <- "int"

# List files in folder
file_list <- list.files(datadir)

# Select set of years and hs versions of interest
hs_years <- data.frame(
  hs_version = c(
    # Length in each should match the set of selected years
    rep("HS96", length(1996:2003)),
    rep("HS02", length(2004:2009)),
    rep("HS07", length(2010:2012)),
    rep("HS12", length(2013:2020))
    # Note: HS17 is not in the current custom ARTIS, but this would be included
    # if an analysis does include HS17 
    #rep("HS17", length(1996:2003))
  ), 
  year = c(
    # HS96 years
    1996:2003,
    # HS02 years
    2004:2009,
    # HS07 years
    2010:2012,
    # HS12 years
    2013:2020
    # HS17 years
  )) 

# Subset file_list to the set of HS versions and years of interest
file_list <- hs_years %>%
  left_join(as.data.frame(file_list) %>%
              separate(file_list, 
                       into = c("data", "est", "hs_version", "year", "csv")) %>%
              mutate(year = as.integer(year)),
            by = c("hs_version", "year")) %>%
  mutate(file_names = paste(data, est, hs_version, year, sep = "_")) %>%
  mutate(file_names = paste0(file_names, ".csv")) %>%
  pull(file_names)

# Loop through selected files and filter each column as desired
# before building back up the file for analysis

# Create empty data frame to build up
df <- data.frame(hs_version = c(), year = c(), 
                 source_country_iso3c = c(), exporter_iso3c = c(), 
                 importer_iso3c = c(), dom_source = c(), 
                 hs6 = c(), sciname = c(), habitat = c(), method = c(), 
                 product_weight_t = c(), live_weight_t = c())

for(i in 1:25){
  # i = 1
  
  print(paste(i, "of", length(file_list), file_list[i], sep = " "))
  
  df_i <- read.csv(file.path(datadir, file_list[i])) %>%
    # Source country
    # Uncomment and add any iso3c codes to filter by
    #filter(source_country_iso3c %in% c()) %>%
    
    # Exporter
    # Uncomment and add any iso3c codes to filter by
    #filter(exporter_iso3c %in% c()) %>%
    
    # Importer
    # Uncomment and add any iso3c codes to filter by
    #filter(importer_iso3c %in% c()) %>%
    
    # HS6 code
    # Add lead zeros to filter hs6 codes 
    # (do this regardless of whether you filter by hs6 codes)
    mutate(hs6 = as.character(hs6)) %>%
    mutate(hs6 = case_when(
      str_length(hs6) == 5 ~ paste("0", hs6, sep = ""),
      TRUE ~ hs6
    )) %>%
    # Uncomment and add any hs6 codes to filter by
    filter(hs6 %in% c("230120", fillet_codes)) %>%
    
    # Export source (domestic vs foreign vs unknown)
    # Uncomment and add any export sources to filter by
    #filter(dom_source %in% c()) %>%
    
    # Scientific names
    # Uncomment and add any scientific names to filter by
    #filter(sciname %in% c()) %>%
    
    # Habitat
    # Uncomment and add any habitats to filter by
    #filter(habitat %in% c()) %>%
    
    # Method
    # Uncomment and add any methods to filter by
    #filter(method %in% c()) %>%
    select(hs_version, year, 
           source_country_iso3c, exporter_iso3c, importer_iso3c, dom_source, 
           hs6, sciname, habitat, method, 
           product_weight_t, live_weight_t)
  
  df <- df %>%
    bind_rows(df_i)
}

## save to rdsi server 
qs::qsave(df, file.path(artis_dir, "full_artis_fm_fillet.qs"))
```



I've received an updated version of the database directly from Jessica Gephart, which contains the domestic production and consumption of fish meal. We will use this instead of the above so that we can incorporate domestic production and consumption fish meal (e.g., how much fish meal does China produce DOMESTICALLY and consume, or not trade).


```{r}
full_artis_new <- qs::qread(file.path(artis_dir, "2024_09_19_consumption_midpoint_all_hs_all_years.qs")) # really big file, nearly 10 gb, takes awhile to load. We'll load it in full and filter for what we need below (fish meal and fillet hs codes)


# lets explore the new data a bit
test <- full_artis_new %>% filter(year == 2020, end_use %in% c("fishmeal", "other"), source_country_iso3c != consumer_iso3c, hs_version == 12) %>%
  mutate(product_weight = consumption_t_capped/2.975207)
sum(test$consumption_t_capped) # 9303891 -  9 million tonnes of live weight? Let's check against what we pulled before
sum(test$consumption_t) # 9425558
sum(test$product_weight) # 3127141 - ok this seems pretty close to what we had before.. off by ~500k tonnes 

old_fm <- qs::qread(file.path(artis_dir, "full_artis_fm_fillet.qs")) %>%
  filter(year == 2020, hs6 == 230120, hs_version == "HS12")


test2 <- old_fm %>% filter(source_country_iso3c == importer_iso3c)
sum(test2$live_weight_t) # 155710.8

sum(old_fm$live_weight_t) # 10397265
sum(old_fm$product_weight_t) # 3494636

test2 <- full_artis_new %>% filter(end_use == "other", year == 2020, hs_version == 17)
test3 <- full_artis_new %>% filter(end_use == "direct human consumption", year == 2020, hs_version == 17)
sum(test3$consumption_t_capped) # 165401647

9162738/165401647 # 0.0553969 ~ 5.5% of tonnage is fish meal

## ok this makes me think the new data is tonnes liveweight. Which is fine. I think Jessica just applies a basic 2.975207x multiplier for the conversion. 


# Select set of years and hs versions of interest
hs_years <- data.frame(
  hs_version_new = c(
    # Length in each should match the set of selected years
    rep(96, length(1996:2003)),
    rep(2, length(2004:2009)),
    rep(7, length(2010:2012)),
    rep(12, length(2013:2016)),
    rep(17, length(2017:2020))
  ), 
  year = c(
    # HS96 years
    1996:2003,
    # HS02 years
    2004:2009,
    # HS07 years
    2010:2012,
    # HS12 years
    2013:2016,
    # HS17 years
    2017:2020
  )) 

# Subset file_list to the set of HS versions and years of interest
full_data_new <- full_artis_new %>%
  left_join(hs_years,
            by = c("year")) %>% 
  filter(hs_version == hs_version_new)

# test <- full_data_new %>% filter(year == 2020, end_use == "fishmeal", source_country_iso3c != consumer_iso3c) %>%
#   mutate(product_weight = consumption_t_capped/2.975207)
# sum(test$consumption_t_capped) 
# sum(test$product_weight)
# ## cool it matches what is was before 


## lets just save the fishmeal part of this 

full_data_fm <- full_data_new %>%
  filter(end_use == "fishmeal") %>% 
  mutate(product_weight_t = consumption_t_capped/2.975207)

# old_fm <- qs::qread(file.path(artis_dir, "full_artis_fm_fillet.qs")) %>%
#   filter(hs6 == 230120) # compare; new data has ~4.1 million rows, old data has 3.8 million rows.. makes sense there would be more rows in the new data, given there is domestic production and consumption included here 

qs::qsave(full_data_fm, file.path(artis_dir, "full_artis_fm_2024_09_19.qs"))

```


```{r}
old_fm <- qs::qread(file.path(artis_dir, "full_artis_fm_fillet.qs")) %>%
  filter(year == 2020, hs6 == 230120, hs_version == "HS12")

artis_taxa <- read.csv(file.path(artis_dir, "artis_full_data/data/attribute tables/sciname.csv")) ## read in attribute table with common names


test <- old_fm %>% 
  left_join(artis_taxa) %>%
  filter(source_country_iso3c %in% c("USA", "NZL", "RUS"),
         str_detect(common_name, "cod|Cod"))

test <- old_fm %>% 
  left_join(artis_taxa) %>%
  filter(source_country_iso3c %in% c("USA", "RUS"),
         genus == "gadus",
         str_detect(common_name, "cod|Cod")) %>%
  distinct(source_country_iso3c, sciname, common_name)



```

